{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10.7_3_inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mewRf49oqrDN"
      },
      "source": [
        "# TensorFlow Object Detection\n",
        "\n",
        "https://github.com/tensorflow/models/tree/master/research/object_detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lobV3VMw3SX"
      },
      "source": [
        "### Монтирование Google Drive\n",
        "Для данного демо нам понадобятся несколько ноутбуков, которые должны работать с одними и теме же данными. Поэтому, чтобы все ноутбуки имели доступ к нужным данным, нам будет необходимо подключить диск Google Drive и сохранять все данные на нём (включая данные, скачанные из интернета).\n",
        "\n",
        "Для монтирования диска нужно выполнить данный блок, перейти по ссылке, получить код, скопировать его в поле ниже (в этом блоке) и нажать Enter\n",
        "\n",
        "После монтирования диск будет находиться здесь: `/content/drive/My Drive`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9D_xkVQw5M9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7339407b-c8f4-431e-a526-6fa8e6f9327b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kh9ujhqw8W7"
      },
      "source": [
        "### Рабочая директория\n",
        "Все данные будем хранить в директории `/content/drive/My Drive/tf_od_demo` (TensorFlow Object Detection Demo)\n",
        "\n",
        "Директория должна быть уже создана (в предыдущем ноутбуке)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhIGiiyZw-i4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7869f0-e8c9-4b57-d4c7-e900cec2e260"
      },
      "source": [
        "%mkdir  \"/content/drive/My Drive/tf_od_demo\"\n",
        "%cd \"/content/drive/My Drive/tf_od_demo\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/My Drive/tf_od_demo’: File exists\n",
            "/content/drive/My Drive/tf_od_demo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6YUNDRmshba"
      },
      "source": [
        "### Загрузка библиотек\n",
        "Загрузка TensorFlow и других библиотек. Кроме того, загрузка различных модулей из пакета `object_detection`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec9nljiMd75n",
        "outputId": "a46e4acb-32df-418a-aa71-41daffa27d3d"
      },
      "source": [
        "if True:\n",
        "    !wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz\n",
        "    !tar -xzf ssd_mobilenet_v1_coco_2018_01_28.tar.gz"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-25 17:20:52--  http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.70.128, 2607:f8b0:4001:c02::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.70.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 76541073 (73M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v1_coco_2018_01_28.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v1_co 100%[===================>]  73.00M  37.8MB/s    in 1.9s    \n",
            "\n",
            "2021-10-25 17:20:54 (37.8 MB/s) - ‘ssd_mobilenet_v1_coco_2018_01_28.tar.gz’ saved [76541073/76541073]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMlMCpSNfh4P"
      },
      "source": [
        "if False:\n",
        "  \n",
        "    !git clone https://github.com/tensorflow/models\n",
        "    !cd models/research && protoc object_detection/protos/*.proto --python_out=.\n",
        "    !cd models/research && export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim && python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSFvWB0yl_cI",
        "outputId": "cb2e9c89-6ded-4674-e327-0eda11881520"
      },
      "source": [
        "!pip install tensorflow-object-detection-api"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-object-detection-api\n",
            "  Downloading tensorflow_object_detection_api-0.1.1.tar.gz (577 kB)\n",
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 25.7 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█████                           | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 276 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 286 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 296 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 307 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 317 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 327 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 337 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 348 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 358 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 368 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 378 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 389 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 399 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 409 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 419 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 430 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 440 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 450 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 460 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 471 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 481 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 491 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 501 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 512 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 522 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 532 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 542 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 552 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 563 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 573 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 577 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (7.1.2)\n",
            "Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.2.2)\n",
            "Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.29.24)\n",
            "Requirement already satisfied: Protobuf in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.17.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (4.2.6)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (1.0.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (2.6.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.5.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.37.0)\n",
            "Collecting twine\n",
            "  Downloading twine-3.4.2-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.1.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.3.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (4.10.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (7.6.5)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.6.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.1.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.3.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (1.15.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (1.0.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (4.8.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (2.6.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (2.11.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->tensorflow-object-detection-api) (22.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->tensorflow-object-detection-api) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->tensorflow-object-detection-api) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->tensorflow-object-detection-api) (2.0.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (0.10.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (4.1.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (1.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->tensorflow-object-detection-api) (21.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->tensorflow-object-detection-api) (0.5.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->tensorflow-object-detection-api) (1.11.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.3.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.12.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.41.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.7.4.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.6.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.12)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (5.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.2.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.6.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.1.2)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.4.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.6.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->tensorflow-object-detection-api) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (3.6.0)\n",
            "Collecting readme-renderer>=21.0\n",
            "  Downloading readme_renderer-30.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting pkginfo>=1.4.2\n",
            "  Downloading pkginfo-1.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Collecting colorama>=0.4.3\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting requests-toolbelt!=0.9.0,>=0.8.0\n",
            "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting keyring>=15.1\n",
            "  Downloading keyring-23.2.1-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: tqdm>=4.14 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (4.62.3)\n",
            "Collecting rfc3986>=1.4.0\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting jeepney>=0.4.2\n",
            "  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting SecretStorage>=3.2\n",
            "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: docutils>=0.13.1 in /usr/local/lib/python3.7/dist-packages (from readme-renderer>=21.0->twine->tensorflow-object-detection-api) (0.17.1)\n",
            "Collecting cryptography>=2.0\n",
            "  Downloading cryptography-35.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 55.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine->tensorflow-object-detection-api) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine->tensorflow-object-detection-api) (2.20)\n",
            "Building wheels for collected packages: tensorflow-object-detection-api\n",
            "  Building wheel for tensorflow-object-detection-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-object-detection-api: filename=tensorflow_object_detection_api-0.1.1-py3-none-any.whl size=844512 sha256=ac197475f7314118b4069ef3db3ee8508c8e65064bab178808e6926dd6314b35\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/7e/a2/461ab817fbaef68ec9cc60df16d3669d1285f032e4c98179bf\n",
            "Successfully built tensorflow-object-detection-api\n",
            "Installing collected packages: jeepney, cryptography, SecretStorage, rfc3986, requests-toolbelt, readme-renderer, pkginfo, keyring, colorama, twine, tensorflow-object-detection-api\n",
            "Successfully installed SecretStorage-3.3.1 colorama-0.4.4 cryptography-35.0.0 jeepney-0.7.1 keyring-23.2.1 pkginfo-1.7.1 readme-renderer-30.0 requests-toolbelt-0.9.1 rfc3986-1.5.0 tensorflow-object-detection-api-0.1.1 twine-3.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kgvSlcJnNkN",
        "outputId": "c93bdb37-675a-42bd-a359-2df0c156270c"
      },
      "source": [
        "!pip install tf_slim"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf_slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 24.8 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20 kB 27.7 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 352 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV4P5gyTWKMI"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import imageio\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, 'models/research')\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from object_detection.utils import dataset_util\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH-PhnfRxrN6"
      },
      "source": [
        "Функция для создания одного обучающего образца\n",
        "В этой функции создаётся экземпляр класса tf.train.Example, который соответствует одной обучающей картике. Ей могут соответствовать несколько ground-truth баундинг боксов. Однако, конкретно в данном примере на картинке есть строго один бокс. В противном случае списки xmins, xmaxs, ymins, ymaxs, classes_text, classes должны иметь соответствующее количество элементов ( = кол-ву боксов на данной картинке).\n",
        "\n",
        "Создавать экземпляры класса tf.train.Example можно произвольным способом. В данном примере на вход в функцию подаётся строка из CSV файла (annot.csv). Главное -- заполнить соовтестсвующие поля словаре feature={...}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KePVEc6xko_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaRDjZ5fxk3C"
      },
      "source": [
        "def create_tf_example(example):\n",
        "  \n",
        "    img_fpath = os.path.join('my_data', example.id)\n",
        "    img = Image.open(img_fpath)\n",
        "    height = img.size[1]\n",
        "    width = img.size[0]\n",
        "    filename = str.encode(example.id)\n",
        "    with open(img_fpath, mode='rb') as f:\n",
        "        encoded_image_data = f.read()\n",
        "    image_format = b'jpeg'\n",
        "\n",
        "    # List of normalized left x coordinates in bounding box (1 per box)\n",
        "    xmins = [example.xmin / float(width)] \n",
        "    # List of normalized right x coordinates in bounding box # (1 per box)\n",
        "    xmaxs = [example.xmax / float(width)] \n",
        "    # List of normalized top y coordinates in bounding box (1 per box)\n",
        "    ymins = [example.ymin / float(height)] \n",
        "    # List of normalized bottom y coordinates in bounding box # (1 per box)\n",
        "    ymaxs = [example.ymax / float(height)] \n",
        "    # List of string class name of bounding box (1 per box)\n",
        "    classes_text = [b'Cube']\n",
        "    # List of integer class id of bounding box (1 per box)\n",
        "    classes = [1]\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "wLO7kSbxx2kD",
        "outputId": "82e5b58b-3261-4177-aa54-2b20a27cc5bd"
      },
      "source": [
        "annot = pd.read_csv('my_data/annot.csv')\n",
        "annot.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>261</td>\n",
              "      <td>260</td>\n",
              "      <td>601</td>\n",
              "      <td>615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.jpg</td>\n",
              "      <td>130</td>\n",
              "      <td>429</td>\n",
              "      <td>401</td>\n",
              "      <td>734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.jpg</td>\n",
              "      <td>254</td>\n",
              "      <td>367</td>\n",
              "      <td>527</td>\n",
              "      <td>672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.jpg</td>\n",
              "      <td>238</td>\n",
              "      <td>348</td>\n",
              "      <td>537</td>\n",
              "      <td>681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.jpg</td>\n",
              "      <td>244</td>\n",
              "      <td>438</td>\n",
              "      <td>524</td>\n",
              "      <td>766</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  xmin  ymin  xmax  ymax\n",
              "0  1.jpg   261   260   601   615\n",
              "1  2.jpg   130   429   401   734\n",
              "2  3.jpg   254   367   527   672\n",
              "3  4.jpg   238   348   537   681\n",
              "4  5.jpg   244   438   524   766"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkPJZnBlyC07"
      },
      "source": [
        "### Создание TFRecord\n",
        "Здесь мы создаём финальный датасет в формате `TFRecord`, который необходим для запуска обучения TF Object Detection. \n",
        "\n",
        "В цикле по всем обучающим образцам создаем `TF Example` и записываем его в `TF Record`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDMqiFMzyE4S"
      },
      "source": [
        "writer = tf.compat.v1.python_io.TFRecordWriter('my_data/train_data.record')\n",
        "\n",
        "for idx, row in annot.iterrows():\n",
        "    tf_example = create_tf_example(row)\n",
        "    writer.write(tf_example.SerializeToString())\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cYVJQo9s7rr"
      },
      "source": [
        "### Загрузка соответствия имён классов и их ID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyPz_t8WWKMQ"
      },
      "source": [
        "PATH_TO_LABELS = 'my_data/cube_label_map.pbtxt'\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2kVvCnqpxhD"
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "!export PYTHONPATH=$PYTHONPATH:models/research:models/research/slim ; python models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path=my_data/pipeline.config \\\n",
        "    --model_dir=my_data/output \\\n",
        "    --num_train_steps=10000 \\\n",
        "    --alsologtostderr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-QlZHYrzwOt"
      },
      "source": [
        "!pip install tf-models-official"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g_fJFU-zjOV"
      },
      "source": [
        "!export PYTHONPATH=$PYTHONPATH:models/research:models/research/slim ; python models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path=my_data/pipeline.config \\\n",
        "    --trained_checkpoint_prefix=my_data/output/model.ckpt-10000 \\\n",
        "    --output_directory=my_data/output/frozen/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2ndufrntJbA"
      },
      "source": [
        "### Загрузка замороженного графа для инференса"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KezjCRVvWKMV"
      },
      "source": [
        "PATH_TO_FROZEN_GRAPH = 'my_data/output/frozen/frozen_inference_graph.pb'\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.compat.v1.GraphDef()\n",
        "    with tf.io.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy1NyTiA7SbY"
      },
      "source": [
        "### Функция для детектирования объектов на одном изображении"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92BHxzcNWKMf"
      },
      "source": [
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
        "                detection_masks_reframed = tf.cast(tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict, feed_dict={image_tensor: image})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[ 'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFvl58oe7Xsv"
      },
      "source": [
        "### Запуск детектрования объектов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7Yrsa0_ai9Z"
      },
      "source": [
        "image_np = imageio.imread('my_data/test.jpg')\n",
        "image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "\n",
        "output_dict = run_inference_for_single_image(image_np_expanded, detection_graph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ubm_EZL7g8-"
      },
      "source": [
        "### Визуализация результатов детектирования\n",
        "Визуализируем получившиеся детекции. Здесь их можно дополнительно отфильтровать по скору, используя `min_score_thresh`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJYzYzyNtzvg"
      },
      "source": [
        "vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "    image_np,\n",
        "    output_dict['detection_boxes'],\n",
        "    output_dict['detection_classes'],\n",
        "    output_dict['detection_scores'],\n",
        "    category_index,\n",
        "    instance_masks=output_dict.get('detection_masks'),\n",
        "    use_normalized_coordinates=True,\n",
        "    line_thickness=4,\n",
        "    min_score_thresh=0.9)\n",
        "\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.imshow(image_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo5fHMDNBn2V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}